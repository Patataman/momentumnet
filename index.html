
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Momentum ResNets &#8212; momentumnet 0.9 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/bootstrap-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-rendered-html.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="API Documentation" href="api.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="_static/js/jquery-1.12.4.min.js "></script>
<script type="text/javascript" src="_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="_static/bootstrap-3.4.1/js/bootstrap.min.js "></script>
<script type="text/javascript" src="_static/bootstrap-sphinx.js "></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="#">
          momentumnet</a>
        <span class="navbar-text navbar-version pull-left"><b>0.9</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="auto_examples/index.html">Examples</a></li>
                <li><a href="api.html">API</a></li>
                <li><a href="https://github.com/michaelsdr/momentumnet">GitHub</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul>
<li class="toctree-l1"><a class="reference internal" href="api.html">API Documentation</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">Momentum ResNets</a><ul>
<li><a class="reference internal" href="#installation">Installation</a></li>
<li><a class="reference internal" href="#quickstart">Quickstart</a></li>
<li><a class="reference internal" href="#momentum-resnets-are-a-drop-in-replacement-for-resnets">Momentum ResNets are a drop-in replacement for ResNets</a></li>
<li><a class="reference internal" href="#memory-savings-when-applying-momentum-resnets-to-transformers">Memory savings when applying Momentum ResNets to Transformers</a></li>
<li><a class="reference internal" href="#dependencies">Dependencies</a></li>
<li><a class="reference internal" href="#bug-reports">Bug reports</a></li>
<li><a class="reference internal" href="#cite">Cite</a></li>
<li><a class="reference internal" href="#api">API</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
            
            
            
              <li class="hidden-sm">
<div id="sourcelink">
  <a href="_sources/index.rst.txt"
     rel="nofollow">Source</a>
</div></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container content-container">
  
  <section id="momentum-resnets">
<h1>Momentum ResNets<a class="headerlink" href="#momentum-resnets" title="Permalink to this headline">¶</a></h1>
<p>Official library for using Momentum Residual Neural Networks [1]. These models extend ResNets
to a larger class of deep learning models that consume less memory. They can be initialized with the
same weights as a pretrained ResNet and are promising in fine-tuning applications.</p>
<section id="installation">
<h2>Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h2>
<p>To install <code class="docutils literal notranslate"><span class="pre">momentumnet</span></code>, you first need to install its dependencies:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ pip install numpy matplotlib torch
</pre></div>
</div>
<p>Then install momentumnet:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ pip install momentumnet
</pre></div>
</div>
<p>If you do not have admin privileges on the computer, use the <code class="docutils literal notranslate"><span class="pre">--user</span></code> flag
with <cite>pip</cite>. To upgrade, use the <code class="docutils literal notranslate"><span class="pre">--upgrade</span></code> flag provided by <cite>pip</cite>.</p>
<p>To check if everything worked fine, you can do:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ python -c &#39;import momentumnet&#39;
</pre></div>
</div>
<p>and it should not give any error message.</p>
</section>
<section id="quickstart">
<h2>Quickstart<a class="headerlink" href="#quickstart" title="Permalink to this headline">¶</a></h2>
<p>The main class is MomentumNet. It creates a Momentum ResNet that iterates</p>
<div class="math notranslate nohighlight">
\[\begin{split}v_{t + 1} = \gamma * v_t + (1 - \gamma) * f_t(x_t) \\
x_{t + 1} = x_t + v_{t + 1}\end{split}\]</div>
<p>These forward equations can be reversed in closed-form,
enabling learning without standard memory consuming backpropagation.
This process trades memory for computations.</p>
<p>To get started, you can create a toy Momentum ResNet by specifying the functions f for the forward pass
and the value of the momentum term, gamma.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">momentumnet</span> <span class="kn">import</span> <span class="n">MomentumNet</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hidden</span> <span class="o">=</span> <span class="mi">8</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="mi">500</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">function</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">hidden</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">d</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mresnet</span> <span class="o">=</span> <span class="n">MomentumNet</span><span class="p">([</span><span class="n">function</span><span class="p">,]</span> <span class="o">*</span> <span class="mi">10</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="momentum-resnets-are-a-drop-in-replacement-for-resnets">
<h2>Momentum ResNets are a drop-in replacement for ResNets<a class="headerlink" href="#momentum-resnets-are-a-drop-in-replacement-for-resnets" title="Permalink to this headline">¶</a></h2>
<p>We can transform a ResNet into a MomentumNet with the same parameters in two lines of codes.
For instance, the following code
instantiates a Momentum ResNet with weights of a pretrained Resnet-101 on ImageNet. We set “use_backprop” to False
so that activations are not saved during the forward pass, allowing smaller memory consumptions.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">momentumnet</span> <span class="kn">import</span> <span class="n">transform_to_momentumnet</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">torchvision.models</span> <span class="kn">import</span> <span class="n">resnet101</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">resnet</span> <span class="o">=</span> <span class="n">resnet101</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mresnet101</span> <span class="o">=</span> <span class="n">transform_to_momentumnet</span><span class="p">(</span><span class="n">resnet</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">use_backprop</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>Importantly, this method also works with Pytorch Transformers module, specifying the residual layers to be turned into their Momentum version.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">momentumnet</span> <span class="kn">import</span> <span class="n">transform_to_momentumnet</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">transformer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Transformer</span><span class="p">(</span><span class="n">num_encoder_layers</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">num_decoder_layers</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mtransformer</span> <span class="o">=</span> <span class="n">transform_to_momentumnet</span><span class="p">(</span><span class="n">transformer</span><span class="p">,</span> <span class="n">sub_layers</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;encoder.layers&quot;</span><span class="p">,</span> <span class="s2">&quot;decoder.layers&quot;</span><span class="p">],</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                                         <span class="n">use_backprop</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">keep_first_layer</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>This initiates a Momentum Transformer with the same weights as the original Transformer.</p>
</section>
<section id="memory-savings-when-applying-momentum-resnets-to-transformers">
<h2>Memory savings when applying Momentum ResNets to Transformers<a class="headerlink" href="#memory-savings-when-applying-momentum-resnets-to-transformers" title="Permalink to this headline">¶</a></h2>
<p>Here is a short <a class="reference external" href="https://colab.research.google.com/drive/1zAyNz2mSxCNcy-rIXLDYS8B2CJXqDYA3?usp=sharing">tutorial</a> showing the memory gains using Momentum Transformers.</p>
</section>
<section id="dependencies">
<h2>Dependencies<a class="headerlink" href="#dependencies" title="Permalink to this headline">¶</a></h2>
<p>These are the dependencies to use momentumnet:</p>
<ul class="simple">
<li><p>numpy (&gt;=1.8)</p></li>
<li><p>matplotlib (&gt;=1.3)</p></li>
<li><p>torch (&gt;= 1.9)</p></li>
<li><p>memory_profiler</p></li>
<li><p>torchvision</p></li>
<li><p>vit_pytorch</p></li>
</ul>
</section>
<section id="bug-reports">
<h2>Bug reports<a class="headerlink" href="#bug-reports" title="Permalink to this headline">¶</a></h2>
<p>Use the <a class="reference external" href="https://github.com/michaelsdr/momentumnet/issues">github issue tracker</a> to report bugs.</p>
</section>
<section id="cite">
<h2>Cite<a class="headerlink" href="#cite" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><dl>
<dt>[1] Michael E. Sander, Pierre Ablin, Mathieu Blondel, Gabriel Peyre. Momentum Residual Neural Networks.</dt><dd><p>Proceedings of the 38th International Conference
on Machine Learning, PMLR 139:9276-9287</p>
<p><a class="reference external" href="https://arxiv.org/abs/2102.07870">https://arxiv.org/abs/2102.07870</a></p>
</dd>
</dl>
</div></blockquote>
</section>
<section id="api">
<h2>API<a class="headerlink" href="#api" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="api.html">API Documentation</a></li>
</ul>
</div>
</section>
</section>


</div>

<!-- Github "fork me" ribbon -->
<a href="https://github.com/michaelsdr/momentumnet"><img style="position: absolute; top: 50px; right: 0; border: 0;"
src="https://camo.githubusercontent.com/652c5b9acfaddf3a9c326fa6bde407b87f7be0f4/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f6f72616e67655f6666373630302e706e67"
alt="Fork me on GitHub"
data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_right_orange_ff7600.png"></a>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2021, Michael Sander.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.3.0.<br/>
    </p>
  </div>
</footer>
  </body>
</html>